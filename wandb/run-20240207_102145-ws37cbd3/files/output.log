`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  6.56it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.37it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.56it/s]
Original Candidate:	  a photo of an astronaut riding a horse on mars
Original Score:	  50.0
Base Candidate:  a photo of an astronaut riding a horse on mars
Base Score:  50.0
w_segement_words:  ['a']
w_segement_words:  ['a', ' ']
w_segement_words:  ['a', ' ', 'p']
w_segement_words:  ['a', ' ', 'p', 'h']
w_segement_words:  ['a', ' ', 'p', 'h', 'o']
w_segement_words:  ['a', ' ', 'p', 'h', 'o', 't']
w_segement_words:  ['a', ' ', 'p', 'h', 'o', 't', 'o']
w_segement:  ['a', ' ', 'p', 'h', 'o', 't', 'o']
w_segement:  []
['sub']
Error occurs (parser) and skip this mutation
w_segement_words:  ['o']
w_segement_words:  ['o', 'f']
w_segement_words:  ['o', 'f', ' ']
w_segement_words:  ['o', 'f', ' ', 'a']
w_segement_words:  ['o', 'f', ' ', 'a', 'n']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm', 'a']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm', 'a', 'r']
w_segement_words:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm', 'a', 'r', 's']
w_segement:  ['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm', 'a', 'r', 's']
['del']
w_segement:  []
Error occurs (parser) and skip this mutation
w_segement:  []
['sub']
Error occurs (parser) and skip this mutation
Candidate:  ["['a', ' ', 'p', 'h', 'o', 't', 'o']", "['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm', 'a', 'r', 's']"]
Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at /home/wenhesun/.cache/huggingface/hub/models--tuner007--pegasus_paraphrase and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  4.45it/s]
Token indices sequence length is longer than the specified maximum sequence length for this model (131 > 77). Running this sequence through the model will result in indexing errors
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['\',\'i \',\'n \',\'g \',\'\',\'a \',\'\',\'h \',\'o \',\'r \',\'s \',\'e \',\'\',\'o \',\'n \',\'\',\'m \',\'a \',\'r \',\'s \']"]']
 10%|█████████████▌                                                                                                                          | 5/50 [00:01<00:11,  3.75it/s]
Traceback (most recent call last):
  File "/home/wenhesun/Plum/pic_score_main.py", line 76, in <module>
    main(args)
  File "/home/wenhesun/Plum/pic_score_main.py", line 20, in main
    trainer.train(instruction, chosen_task_name="pic_score", args = args)
  File "/home/wenhesun/Plum/trainers/HS_trainer.py", line 253, in train
    w_m_score = self.score(w_m, c+1, args=args)
  File "/home/wenhesun/Plum/trainers/Pic_HS_trainer.py", line 141, in score
    image = sd_pipe(prompt).images[0]
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py", line 1002, in __call__
    noise_pred = self.unet(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_condition.py", line 1177, in forward
    sample = upsample_block(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_blocks.py", line 2353, in forward
    hidden_states = resnet(hidden_states, temb, scale=lora_scale)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/resnet.py", line 231, in forward
    self.time_emb_proj(temb, scale)[:, :, None, None]
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/lora.py", line 430, in forward
    out = super().forward(hidden_states)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt