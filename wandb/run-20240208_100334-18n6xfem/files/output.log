`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  4.84it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.35it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.55it/s]
Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at /home/wenhesun/.cache/huggingface/hub/models--tuner007--pegasus_paraphrase and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Original Candidate:	  a photo of an astronaut riding a horse on mars
Original Score:	  50.0
Current Iteration:  1
Base Candidate:  a photo of an astronaut riding a horse on mars
Base Score:  50.0
['a photo']
Candidate:  a photo
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.97it/s]






100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.55it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.55it/s]
Candidate Score:  0.2844868053216487
['a photo']
Running LLM mutation
Error occurs (parser) and skip this mutation 2
Candidate:
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.17it/s]






100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.55it/s]
 16%|█████████████████████▊                                                                                                                  | 8/50 [00:02<00:12,  3.44it/s]
Traceback (most recent call last):
  File "/home/wenhesun/Plum/pic_score_main.py", line 78, in <module>
    main(args)
  File "/home/wenhesun/Plum/pic_score_main.py", line 22, in main
    trainer.train(instruction, chosen_task_name="pic_score", args = args)
  File "/home/wenhesun/Plum/trainers/HS_trainer.py", line 248, in train
    w_m_score = self.score(w_m, c+1, args=args)
  File "/home/wenhesun/Plum/trainers/Pic_HS_trainer.py", line 141, in score
    image = sd_pipe(prompt).images[0]
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py", line 1002, in __call__
    noise_pred = self.unet(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_condition.py", line 1177, in forward
    sample = upsample_block(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_blocks.py", line 2354, in forward
    hidden_states = attn(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/transformer_2d.py", line 392, in forward
    hidden_states = block(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/attention.py", line 366, in forward
    attn_output = self.attn2(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/attention_processor.py", line 527, in forward
    return self.processor(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/attention_processor.py", line 770, in __call__
    query = attn.head_to_batch_dim(query)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/attention_processor.py", line 571, in head_to_batch_dim
    tensor = tensor.reshape(batch_size * head_size, seq_len, dim // head_size)
KeyboardInterrupt