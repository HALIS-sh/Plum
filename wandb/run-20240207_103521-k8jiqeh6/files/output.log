`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.89it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:15<00:00,  3.21it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.56it/s]
Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at /home/wenhesun/.cache/huggingface/hub/models--tuner007--pegasus_paraphrase and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
Original Candidate:	  a photo of an astronaut riding a horse on mars
Original Score:	  50.0
Base Candidate:  a photo of an astronaut riding a horse on mars
Base Score:  50.0
w_segement1:  ['a photo']
w_segement_words:  ['a photo']
<class 'str'>
w_segement2:  ['a photo']
['sub']
w_segement3:  ['a photo']
w_segement1:  []
<class 'str'>
w_segement2:  []
['del']
Error occurs (parser) and skip this mutation
w_segement1:  ['of an astronaut riding a horse on mars']
w_segement_words:  ['of an astronaut riding a horse on mars']
<class 'str'>
w_segement2:  ['of an astronaut riding a horse on mars']
w_segement3:  ['of An individual who is an individual who is a person who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual riding a horse on mars']
w_segement1:  []
<class 'str'>
w_segement2:  []
['del']
Error occurs (parser) and skip this mutation
w_segement1:  []
<class 'str'>
w_segement2:  []
w_segement3:  []
Candidate:  ["['a photo']", "['of An individual who is an individual who is a person who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual who is an individual riding a horse on mars']", '[]']
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  4.21it/s]
Token indices sequence length is longer than the specified maximum sequence length for this model (86 > 77). Running this sequence through the model will result in indexing errors
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['mars \']", \'[]\']']
  0%|                                                                                                                                                | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/wenhesun/Plum/pic_score_main.py", line 76, in <module>
    main(args)
  File "/home/wenhesun/Plum/pic_score_main.py", line 20, in main
    trainer.train(instruction, chosen_task_name="pic_score", args = args)
  File "/home/wenhesun/Plum/trainers/HS_trainer.py", line 255, in train
    w_m_score = self.score(w_m, c+1, args=args)
  File "/home/wenhesun/Plum/trainers/Pic_HS_trainer.py", line 141, in score
    image = sd_pipe(prompt).images[0]
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py", line 1002, in __call__
    noise_pred = self.unet(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_condition.py", line 1177, in forward
    sample = upsample_block(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_blocks.py", line 2354, in forward
    hidden_states = attn(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/transformer_2d.py", line 327, in forward
    hidden_states = self.norm(hidden_states)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 272, in forward
    return F.group_norm(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/functional.py", line 2516, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
KeyboardInterrupt