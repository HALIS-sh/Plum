`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.22it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:15<00:00,  3.17it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.55it/s]
Original Candidate:	  a photo of an astronaut riding a horse on mars
Original Score:	  50.0
Base Candidate:  a photo of an astronaut riding a horse on mars
Base Score:  50.0
['del']
['del']
Error occurs (parser) and skip this mutation
['del']
['swap']
Error occurs (parser) and skip this mutation
Error occurs (parser) and skip this mutation
Candidate:  ["['a', ' ', 'p', 'h', '', 't', '']", "['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm', 'a', 'r', 's']"]
Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at /home/wenhesun/.cache/huggingface/hub/models--tuner007--pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.11it/s]
Token indices sequence length is longer than the specified maximum sequence length for this model (128 > 77). Running this sequence through the model will result in indexing errors
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['\',\'n \',\'g \',\'\',\'a \',\'\',\'h \',\'o \',\'r \',\'s \',\'e \',\'\',\'o \',\'n \',\'\',\'m \',\'a \',\'r \',\'s \']"]']






100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.55it/s]
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['\',\'n \',\'g \',\'\',\'a \',\'\',\'h \',\'o \',\'r \',\'s \',\'e \',\'\',\'o \',\'n \',\'\',\'m \',\'a \',\'r \',\'s \']"]']







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.54it/s]
Candidate Score:  0.5343340744730085
['del']
['sub']
Error occurs (parser) and skip this mutation
['del']
Error occurs (parser) and skip this mutation
['del']
Error occurs (parser) and skip this mutation
Candidate:  ["['a', ' ', 'p', 'h', 'o', 't', 'o']", "['o', 'f', ' ', 'a', 'n', ' ', 'a', 's', 't', 'r', 'o', 'n', 'a', 'u', 't', ' ', 'r', 'i', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'h', 'o', 'r', 's', 'e', ' ', 'o', 'n', ' ', 'm', 'a', 'r', 's']"]
Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.29it/s]
Token indices sequence length is longer than the specified maximum sequence length for this model (131 > 77). Running this sequence through the model will result in indexing errors
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['\',\'i \',\'n \',\'g \',\'\',\'a \',\'\',\'h \',\'o \',\'r \',\'s \',\'e \',\'\',\'o \',\'n \',\'\',\'m \',\'a \',\'r \',\'s \']"]']







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.55it/s]
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['\',\'i \',\'n \',\'g \',\'\',\'a \',\'\',\'h \',\'o \',\'r \',\'s \',\'e \',\'\',\'o \',\'n \',\'\',\'m \',\'a \',\'r \',\'s \']"]']




 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 35/50 [00:09<00:04,  3.50it/s]
Traceback (most recent call last):
  File "/home/wenhesun/Plum/pic_score_main.py", line 76, in <module>
    main(args)
  File "/home/wenhesun/Plum/pic_score_main.py", line 20, in main
    trainer.train(instruction, chosen_task_name="pic_score", args = args)
  File "/home/wenhesun/Plum/trainers/HS_trainer.py", line 252, in train
    w_m_score = self.score(w_m, c+1, args=args)
  File "/home/wenhesun/Plum/trainers/Pic_HS_trainer.py", line 141, in score
    image = sd_pipe(prompt).images[0]
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py", line 1002, in __call__
    noise_pred = self.unet(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_condition.py", line 1177, in forward
    sample = upsample_block(
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/unet_2d_blocks.py", line 2353, in forward
    hidden_states = resnet(hidden_states, temb, scale=lora_scale)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/diffusers/models/resnet.py", line 248, in forward
    hidden_states = self.nonlinearity(hidden_states)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 391, in forward
    return F.silu(input, inplace=self.inplace)
  File "/home/wenhesun/anaconda3/envs/stable-diffusion/lib/python3.9/site-packages/torch/nn/functional.py", line 2048, in silu
    return torch._C._nn.silu(input)
KeyboardInterrupt